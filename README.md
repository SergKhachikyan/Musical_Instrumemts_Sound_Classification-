# ğŸµ Musical Instruments Sound Classification

This project focuses on classifying musical instrument sounds using machine learning techniques.  
It includes audio preprocessing, feature extraction (MFCC), model training, evaluation, and visualization of results.

## ğŸ“ Project Structure

```
Musical_Instrumemts_Sound_Classification-/
â”œâ”€â”€ data/                # Raw audio files
â”œâ”€â”€ features/            # Extracted MFCC features
â”œâ”€â”€ models/              # Saved models
â”œâ”€â”€ notebooks/           # Jupyter notebooks for analysis
â”œâ”€â”€ utils/               # Utility scripts
â”œâ”€â”€ results/             # Reports and visualizations
â”œâ”€â”€ main.py              # Entry point for training/evaluation
â””â”€â”€ requirements.txt     # Project dependencies
```

## ğŸš€ Quick Start

1. Clone the repository:  
```  
git clone https://github.com/SergKhachikyan/London_House_Price_Prediction_Advanced_Techniques.git
```
2. Change directory:
```
cd Musical_Instrumemts_Sound_Classification
```
3. Create virtual environment:
```
py -m venv venv
```
4. Activate virtual environment:
```
venv\Scripts\activate
```
5. Update the package manager:
```
py -m pip install -U pip
```
6.Install dependencies:
```
pip install -r requirements.txt  
```
7.Launch the notebook:
```
jupyter notebook untitled.ipynb
```  
## ğŸ“Š Technologies Used

- Python 3.x  
- [Librosa](https://librosa.org/) â€” Audio feature extraction  
- [Scikit-learn](https://scikit-learn.org/) â€” Machine learning models  
- NumPy / Pandas / Matplotlib â€” Data processing and visualization  
- Seaborn â€” Advanced plots and statistical graphs  
- Jupyter â€” Interactive analysis  

## ğŸ“ˆ Results

> Sample metrics (replace with actual results if needed):

- **Accuracy:** 92.3%  
- **Confusion Matrix:** `results/confusion_matrix.png`  
- **Classification Report:** `results/report.txt`  

## ğŸ“Š Visualization

Visualization is an important part of this project and includes:

- ğŸ“ˆ **MFCC plots**: Temporal and frequency-based feature graphs  
- ğŸŒ€ **Spectrograms**: Visual representation of sound signals  
- ğŸ“‰ **Confusion matrix**: Evaluate classification performance  
- ğŸ“Š **Distribution graphs**: Audio duration, class frequency, etc.

![Bisli (56)](https://github.com/user-attachments/assets/21efc1df-b3ed-48ac-9d50-5ab814bb702a)
![Bom (2)](https://github.com/user-attachments/assets/4d64b681-f547-4dd2-9ce1-42b6027ce184)
![Ksing Kynthei (1)](https://github.com/user-attachments/assets/4e633e96-161c-4f53-9c79-8581198ed53f)
![Ksing Shynrang (10)](https://github.com/user-attachments/assets/a8bc8f54-0cf8-4c72-bfad-00ebb5ffa497)
![Kynshaw (1)](https://github.com/user-attachments/assets/7af59a1e-b73f-42dd-bef5-39d88b47f357)
![Pdiah (3)](https://github.com/user-attachments/assets/1356b77b-fb94-4d0a-a11c-162068db7fe0)


All visual outputs are saved in the `results/` directory and also displayed within the `notebooks/`.

## ğŸ“¦ Features

- Audio preprocessing (trimming, normalization)  
- MFCC feature extraction  
- Model training and evaluation  
- Data and results visualization  

## ğŸ“ Roadmap

- [ ] Add CNN-based model using spectrograms  
- [ ] Streamlit web interface for real-time demo  
- [ ] Dataset expansion with additional instruments  

## ğŸ“š Dataset

Specify your dataset source here.  
Example: [UrbanSound8K](https://urbansounddataset.weebly.com/urbansound8k.html) or a custom audio dataset.

## ğŸ¤ Contributing

Pull requests and issues are welcome!  
Feel free to open discussions for ideas, bugs, or improvements.
